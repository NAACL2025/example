Welcome to KnowLLM 2024, the inaugural workshop on knowledgeable language models. Co-located with ACL 2024, this workshop is scheduled for August 16, 2024 to be held in Bangkok, Thailand.\\
\\
Knowledge has been an important prerequisite for a variety of NLP applications, and is typically sourced from either structured knowledge sources such as knowledge bases and dictionaries or unstructured knowledge sources such as Wikipedia documents. More recently, researchers have discovered that language models already possess a significant amount of knowledge through pretraining: LLMs can be used to generate commonsense knowledge and factual knowledge context for question answering. While the results are encouraging, there are still lingering questions: Where does this knowledge come from? How much do language models know? Is this knowledge reliable? If some knowledge is wrong, can we fix it?\\
\\
In response to these questions, the KnowLLM workshop examines the lifecycle of knowledge within language models: (1) the emergence of knowledge through language model pre-training; (2) injection of external knowledge; (3) the updating and modification of knowledge; (4) probing and generation of knowledge. Currently, researchers that focus on different stages in this lifecycle are scattered across different sub-communities within NLP: probing knowledge and editing knowledge is often associated with the interpretability track while injecting knowledge is often application-specific and is discussed within the dialog, QA, IE, or summarization tracks. The workshop seeks to bring these researchers together and facilitate collaboration to create a more holistic view of the problem.\\
\\
The KnowLLM workshop is also closely related to some of the core challenges involving LM research: reducing hallucination, improving interpretability, and making models extensible. Although such challenges are still open, it is clear that knowledge plays a key role: (1) attribution to sources or providing the relevant knowledge during generation can mitigate hallucination; (2) being able to locate and trace the knowledge provides insight into the LM's inner workings; (3) being able to efficiently adapt to domain knowledge or integrate updated facts improves extensibility.\\
\\
This year, there were a total of 78 archival and non-archival submissions to the KnowLLM workshop, of which a total of 48 were accepted. Among these works, 16 have been included in our proceedings and 19 are included in ACL Findings.\\
\\
In addition to oral and poster sessions where accepted works will be presented, the Workshop also will also host talks and a panel discussion with six invited speakers: Isabelle Augenstein, Peter Clark, Tatsunori Hashimoto, Ed Hovy, Hannah Rashkin, and Luke Zettlemoyer. \\
\\
Finally, we would like to express our gratitude to all the authors, committee members, invited speakers, and participants for helping make this workshop possible. We would also like to gratefully acknowledge our sponsor, Amazon, for their support.\\
